{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzS2nSzMdyQ8CkOq5R3TOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlitsidis/DataStructuresProject/blob/main/RAGChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fECcQ3vi-lUu"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-llms-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive\n"
      ],
      "metadata": {
        "id": "rwKCB8V8fMWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tPMrwYm4cCX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3bb796-0cd3-4df9-f2ed-4071eea9adb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Test PDF"
      ],
      "metadata": {
        "id": "4zTqOR13fP3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "data = SimpleDirectoryReader(\"/content/drive/MyDrive/Elpedison/\").load_data()"
      ],
      "metadata": {
        "id": "GxAjqYZjfS_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDFReader"
      ],
      "metadata": {
        "id": "-QlMMXOKXfQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "Sih2EeRVXe7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Model and Index the PDF"
      ],
      "metadata": {
        "id": "USrHAYsVlqzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Optional\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "HF_TOKEN: Optional[str] = os.getenv(\"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\")\n",
        "\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "   model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")\n",
        "\n",
        "# embed_model = HuggingFaceEmbedding( model_name = \"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "# embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "# print(len(embeddings))\n",
        "# print(embeddings[:5])"
      ],
      "metadata": {
        "id": "RnCjlPIFlYjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(data)"
      ],
      "metadata": {
        "id": "wxsrIocQxELT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPENAI API KEY HERE (IF POSSIBLE)"
      ],
      "metadata": {
        "id": "2hxESLkKydCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "DXngLEQzya_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPENAI LLM"
      ],
      "metadata": {
        "id": "gyJ5I8VwgSz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "\n",
        "response = OpenAI().complete(\"What is the primary goal in performance analysis\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1CWXJungU5r",
        "outputId": "0b4cbde0-456e-44f3-f456-79f03faf7878"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The primary goal in performance analysis is to evaluate and improve the performance of individuals, teams, or organizations in order to achieve better results and outcomes. This involves identifying strengths and weaknesses, setting performance goals, measuring progress, and implementing strategies to enhance performance. Performance analysis helps to identify areas for improvement, optimize resources, and drive continuous improvement in order to achieve peak performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is the primary goal in performance analysis\")\n",
        "print(response , \"\\n\")\n",
        "\n",
        "#response = query_engine.query(\"What is the lube oil system of the steam turbine composed of?\")\n",
        "#print(response , \"\\n\")\n",
        "#\n",
        "#response = query_engine.query(\"What do you know about turning gear 13MAK10AE001?\")\n",
        "#print(response)"
      ],
      "metadata": {
        "id": "QZcY3ZNTyQRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c5393c-d7c8-4f3e-d79f-3f3dedecb23a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The primary goal in performance analysis is to calculate the net electric power output and thermal efficiency of the Gas Turbine Combined Cycle (GTCC) power plant at both design and off-design conditions. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core import get_response_synthesizer\n",
        "\n",
        "\n",
        "# configure retriever\n",
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=10,\n",
        ")\n",
        "\n",
        "# configure response synthesizer\n",
        "response_synthesizer = get_response_synthesizer()\n",
        "\n",
        "# assemble query engine\n",
        "query_engine2 = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
        ")\n",
        "\n",
        "# query\n",
        "response = query_engine2.query(\"What is the primary goal in performance analysis\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mwftovgXOe7",
        "outputId": "d7b6968d-93dd-4ffc-c70f-d0ff0c717025"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The primary goal in performance analysis is to determine the net electric power output and thermal efficiency of the Gas Turbine Combined Cycle (GTCC) power plant under various operating conditions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating**"
      ],
      "metadata": {
        "id": "9v5_jDXzfnkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "\n",
        "# define evaluator\n",
        "evaluator = FaithfulnessEvaluator(llm=llm)\n",
        "\n",
        "# query\n",
        "response = query_engine.query(\"What is the primary goal in performance analysis\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "MuoAAWPqfpzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}